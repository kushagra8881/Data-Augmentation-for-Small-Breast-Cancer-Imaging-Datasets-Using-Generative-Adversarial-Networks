{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on images in: generated_images_8/\n",
      "Using device: cuda\n",
      "\n",
      "Evaluation Results for generated_images_8/:\n",
      "Accuracy: 0.9300\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.92      0.94      0.93        50\n",
      "Malignant (1)       0.94      0.92      0.93        50\n",
      "\n",
      "     accuracy                           0.93       100\n",
      "    macro avg       0.93      0.93      0.93       100\n",
      " weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[47  3]\n",
      " [ 4 46]]\n",
      "\n",
      "Sample Predictions:\n",
      "Image: generated7_0.png | True: 0 | Pred: 0 | Confidence: 0.96\n",
      "Image: generated7_1.png | True: 0 | Pred: 0 | Confidence: 0.94\n",
      "Image: generated7_10.png | True: 0 | Pred: 0 | Confidence: 0.84\n",
      "Image: generated7_11.png | True: 0 | Pred: 0 | Confidence: 0.92\n",
      "Image: generated7_12.png | True: 0 | Pred: 0 | Confidence: 0.75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"generated_images_8/\"  # Directory with 0/ and 1/ subdirectories\n",
    "MODEL_PATH =\"best_model_des.pth\"  # Path to your saved model\n",
    "IMG_SIZE = (256, 256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "class DenseCNN(nn.Module):\n",
    "    def __init__(self, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(base_channels*8, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = DenseCNN().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def evaluate_model(directory_path):\n",
    "    \"\"\"Evaluate model on images in directory structure\"\"\"\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    confidences = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Walk through directory structure\n",
    "    for label in ['0', '1']:\n",
    "        class_dir = os.path.join(directory_path, label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                img_tensor = transform(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(img_tensor)\n",
    "                    probabilities = torch.softmax(output, dim=1)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    confidence = probabilities[0][predicted].item()\n",
    "                \n",
    "                # Store results\n",
    "                true_labels.append(int(label))\n",
    "                pred_labels.append(predicted.item())\n",
    "                confidences.append(confidence)\n",
    "                image_paths.append(img_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    print(f\"\\nEvaluation Results for {directory_path}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=['Benign (0)', 'Malignant (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, pred_labels))\n",
    "    \n",
    "    # Print some examples\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    for i in range(min(5, len(image_paths))):\n",
    "        print(f\"Image: {os.path.basename(image_paths[i])} | \"\n",
    "              f\"True: {true_labels[i]} | \"\n",
    "              f\"Pred: {pred_labels[i]} | \"\n",
    "              f\"Confidence: {confidences[i]:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'true_labels': true_labels,\n",
    "        'pred_labels': pred_labels,\n",
    "        'confidences': confidences,\n",
    "        'image_paths': image_paths\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Evaluating model on images in: {DATA_PATH}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    results = evaluate_model(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203261/45189740.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on images in: generated_images_1/\n",
      "Using device: cuda\n",
      "Loading model from: best_model_full_data.pth\n",
      "\n",
      "Evaluation Results for generated_images_1/:\n",
      "Accuracy: 0.7000\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.64      0.92      0.75        25\n",
      "Malignant (1)       0.86      0.48      0.62        25\n",
      "\n",
      "     accuracy                           0.70        50\n",
      "    macro avg       0.75      0.70      0.68        50\n",
      " weighted avg       0.75      0.70      0.68        50\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23  2]\n",
      " [13 12]]\n",
      "\n",
      "Sample Predictions:\n",
      "Image: generated_0.png | True: 0 | Pred: 0 | Confidence: 0.86\n",
      "Image: generated_1.png | True: 0 | Pred: 0 | Confidence: 0.83\n",
      "Image: generated_10.png | True: 0 | Pred: 0 | Confidence: 0.98\n",
      "Image: generated_11.png | True: 0 | Pred: 0 | Confidence: 0.94\n",
      "Image: generated_12.png | True: 0 | Pred: 0 | Confidence: 0.67\n",
      "\n",
      "Evaluation completed successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"generated_images_1/\"  # Directory with 0/ and 1/ subdirectories\n",
    "MODEL_PATH = \"best_model_des.pth\"  # Updated to match trained model\n",
    "IMG_SIZE = (256, 256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Updated Model Architecture to match training\n",
    "class DenseCNN(nn.Module):\n",
    "    def __init__(self, base_channels=64):  # Increased base channels\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Dense block 1\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Dense block 2 with residual connection\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*4, base_channels*2, 3, padding=1),  # Match input channels\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.downsample3 = nn.Conv2d(base_channels*2, base_channels*2, 1)  # Identity mapping\n",
    "        \n",
    "        # Dense block 3 with residual connection\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels*8, base_channels*2, 3, padding=1),  # Match input channels\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.downsample4 = nn.Conv2d(base_channels*2, base_channels*2, 1)  # Identity mapping\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Final pooling and classifier\n",
    "        self.final_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(base_channels*2, base_channels),\n",
    "            nn.BatchNorm1d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(base_channels, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)  # 256x256 -> 128x128\n",
    "        x2 = self.conv2(x1)  # 128x128 -> 64x64\n",
    "        \n",
    "        # First residual block\n",
    "        identity = x2\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = x3 + self.downsample3(identity)\n",
    "        \n",
    "        # Second residual block\n",
    "        identity = x3\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = x4 + self.downsample4(identity)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention = self.attention(x4)\n",
    "        x4 = x4 * attention\n",
    "        \n",
    "        # Final classification\n",
    "        x4 = self.final_pool(x4)\n",
    "        return self.classifier(x4)\n",
    "\n",
    "# Load the trained model\n",
    "model = DenseCNN().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing (should match training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def evaluate_model(directory_path):\n",
    "    \"\"\"Evaluate model on images in directory structure\"\"\"\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    confidences = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Walk through directory structure\n",
    "    for label in ['0', '1']:\n",
    "        class_dir = os.path.join(directory_path, label)  # Updated to look in rf subdirectory\n",
    "        \n",
    "            \n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image {img_path}\")\n",
    "                    continue\n",
    "                    \n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                img_tensor = transform(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(img_tensor)\n",
    "                    probabilities = torch.softmax(output, dim=1)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    confidence = probabilities[0][predicted].item()\n",
    "                \n",
    "                # Store results\n",
    "                true_labels.append(int(label))\n",
    "                pred_labels.append(predicted.item())\n",
    "                confidences.append(confidence)\n",
    "                image_paths.append(img_path)\n",
    "    \n",
    "    if not true_labels:\n",
    "        print(\"No images found for evaluation\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    print(f\"\\nEvaluation Results for {directory_path}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=['Benign (0)', 'Malignant (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, pred_labels))\n",
    "    \n",
    "    # Print some examples\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    for i in range(min(5, len(image_paths))):\n",
    "        print(f\"Image: {os.path.basename(image_paths[i])} | \"\n",
    "              f\"True: {true_labels[i]} | \"\n",
    "              f\"Pred: {pred_labels[i]} | \"\n",
    "              f\"Confidence: {confidences[i]:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'true_labels': true_labels,\n",
    "        'pred_labels': pred_labels,\n",
    "        'confidences': confidences,\n",
    "        'image_paths': image_paths\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Evaluating model on images in: {DATA_PATH}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    \n",
    "    results = evaluate_model(DATA_PATH)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\nEvaluation completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nEvaluation failed - no valid images found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
