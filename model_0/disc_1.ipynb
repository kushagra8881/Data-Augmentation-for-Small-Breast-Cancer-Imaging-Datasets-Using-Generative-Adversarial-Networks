{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e95c04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on images in: generated_images_1_1/\n",
      "Using device: cuda\n",
      "\n",
      "Evaluation Results for generated_images_1_1/:\n",
      "Accuracy: 0.8200\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.79      0.88      0.83        50\n",
      "Malignant (1)       0.86      0.76      0.81        50\n",
      "\n",
      "     accuracy                           0.82       100\n",
      "    macro avg       0.82      0.82      0.82       100\n",
      " weighted avg       0.82      0.82      0.82       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44  6]\n",
      " [12 38]]\n",
      "\n",
      "Sample Predictions:\n",
      "Image: generated1_0.png | True: 0 | Pred: 0 | Confidence: 0.94\n",
      "Image: generated1_1.png | True: 0 | Pred: 0 | Confidence: 0.85\n",
      "Image: generated1_10.png | True: 0 | Pred: 1 | Confidence: 0.61\n",
      "Image: generated1_11.png | True: 0 | Pred: 0 | Confidence: 0.97\n",
      "Image: generated1_12.png | True: 0 | Pred: 0 | Confidence: 0.97\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"generated_images_1_1/\"  # Directory with 0/ and 1/ subdirectories\n",
    "MODEL_PATH =\"best_model_des.pth\"  # Path to your saved model\n",
    "IMG_SIZE = (256, 256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "class DenseCNN(nn.Module):\n",
    "    def __init__(self, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(base_channels*8, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = DenseCNN().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def evaluate_model(directory_path):\n",
    "    \"\"\"Evaluate model on images in directory structure\"\"\"\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    confidences = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Walk through directory structure\n",
    "    for label in ['0', '1']:\n",
    "        class_dir = os.path.join(directory_path, label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                img_tensor = transform(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(img_tensor)\n",
    "                    probabilities = torch.softmax(output, dim=1)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    confidence = probabilities[0][predicted].item()\n",
    "                \n",
    "                # Store results\n",
    "                true_labels.append(int(label))\n",
    "                pred_labels.append(predicted.item())\n",
    "                confidences.append(confidence)\n",
    "                image_paths.append(img_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    print(f\"\\nEvaluation Results for {directory_path}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=['Benign (0)', 'Malignant (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, pred_labels))\n",
    "    \n",
    "    # Print some examples\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    for i in range(min(5, len(image_paths))):\n",
    "        print(f\"Image: {os.path.basename(image_paths[i])} | \"\n",
    "              f\"True: {true_labels[i]} | \"\n",
    "              f\"Pred: {pred_labels[i]} | \"\n",
    "              f\"Confidence: {confidences[i]:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'true_labels': true_labels,\n",
    "        'pred_labels': pred_labels,\n",
    "        'confidences': confidences,\n",
    "        'image_paths': image_paths\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Evaluating model on images in: {DATA_PATH}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    results = evaluate_model(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e0907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on images in: generated_images_1_1_1/\n",
      "Using device: cuda\n",
      "\n",
      "Evaluation Results for generated_images_1_1_1/:\n",
      "Accuracy: 0.8249\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.81      0.83      0.82       143\n",
      "Malignant (1)       0.84      0.82      0.83       154\n",
      "\n",
      "     accuracy                           0.82       297\n",
      "    macro avg       0.82      0.82      0.82       297\n",
      " weighted avg       0.83      0.82      0.82       297\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[118  25]\n",
      " [ 27 127]]\n",
      "\n",
      "Sample Predictions:\n",
      "Image: 0.png | True: 0 | Pred: 1 | Confidence: 0.62\n",
      "Image: 1.png | True: 0 | Pred: 1 | Confidence: 0.58\n",
      "Image: 100.png | True: 0 | Pred: 0 | Confidence: 0.99\n",
      "Image: 101.png | True: 0 | Pred: 0 | Confidence: 0.97\n",
      "Image: 102.png | True: 0 | Pred: 0 | Confidence: 0.97\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"generated_images_1_1_1/\"  # Directory with 0/ and 1/ subdirectories\n",
    "MODEL_PATH =\"best_model_des.pth\"  # Path to your saved model\n",
    "IMG_SIZE = (256, 256)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "class DenseCNN(nn.Module):\n",
    "    def __init__(self, base_channels=32):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(base_channels*8, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = DenseCNN().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def evaluate_model(directory_path):\n",
    "    \"\"\"Evaluate model on images in directory structure\"\"\"\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    confidences = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Walk through directory structure\n",
    "    for label in ['0', '1']:\n",
    "        class_dir = os.path.join(directory_path, label)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                # Load and preprocess image\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                img_tensor = transform(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "                \n",
    "                # Get prediction\n",
    "                with torch.no_grad():\n",
    "                    output = model(img_tensor)\n",
    "                    probabilities = torch.softmax(output, dim=1)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    confidence = probabilities[0][predicted].item()\n",
    "                \n",
    "                # Store results\n",
    "                true_labels.append(int(label))\n",
    "                pred_labels.append(predicted.item())\n",
    "                confidences.append(confidence)\n",
    "                image_paths.append(img_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    print(f\"\\nEvaluation Results for {directory_path}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels, target_names=['Benign (0)', 'Malignant (1)']))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, pred_labels))\n",
    "    \n",
    "    # Print some examples\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    for i in range(min(5, len(image_paths))):\n",
    "        print(f\"Image: {os.path.basename(image_paths[i])} | \"\n",
    "              f\"True: {true_labels[i]} | \"\n",
    "              f\"Pred: {pred_labels[i]} | \"\n",
    "              f\"Confidence: {confidences[i]:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'true_labels': true_labels,\n",
    "        'pred_labels': pred_labels,\n",
    "        'confidences': confidences,\n",
    "        'image_paths': image_paths\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Evaluating model on images in: {DATA_PATH}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    results = evaluate_model(DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
